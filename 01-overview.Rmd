# Overview 

## The first wave

Using computational methods to infer linguistic phylogenies has been flourishing in the recent decades. To put it more accurately, the term *computational* refers specifically to the Bayesian approach to linguistic phylogenetic estimation. The *first wave* of this line of research—[lexicostatistics](https://en.wikipedia.org/wiki/Lexicostatistics) and [glottochronology](https://en.wikipedia.org/wiki/Glottochronology)—has been extensively criticized. 

Lexicostatistics estimates linguistic similarity based on proportions of shared cognates in a set of core vocabulary, for instance, a [Swadesh 100 list](https://en.wikipedia.org/wiki/Swadesh_list) [@swadesh1955] or 200 list [@swadesh1952]. Built upon lexicostatistics, glottochronology dates lineage-splitting between language pairs. Arguments against these early methods are well-described in the literature [@bowern2018; @dunn2015; @goldstein2020]^[I largely agree with these criticisms; however, this line of research is not fully rejected by linguists. See @zhang2016 for recent efforts to validate lexicostatistics from a mathematical perspective.]. To briefly summarize, they are flawed in terms of *data* and *assumptions*. 

On one hand, this line of research is entirely based on cognates, which simply captures lexical similarity or linguistic distance, instead of linguistic phylogenies. A cognate list as such does not inform us of the reasons why cognates exist in the first place; moreover, it does not distinguish *shared retention* from *shared innovation*, despite the fact that the latter is more informative when constructing a phylogenetic tree^[Also see [Häkkinen (2012)](http://www.elisanet.fi/alkupera/Problems_of_phylogenetics.pdf)'s comments on @bouckaert2012 for a similar reason.]. 

> It is important to keep in mind that shared retentions are of practically no value for subgrouping. A shared retention is merely something that different daughter languages inherit unchanged from the proto-language regardless of whether the daughters belong to the same subgroup or not [...] Shared retentions just do not reveal which languages share a period of common history after the break-up of the proto-language [@campbell2013, pp.33-35].

On the other hand, glottochronology, according to its formula^[see @bowern2018 for a detailed explanation of the formula], assumes that language change follows a single, constant rate, instead of allowing variation in the rate of change, which often occurs in language families like Indo-European.


## Bayesian phylogenetics

Unlike the above approaches, [Bayesian phylogenetics](https://en.wikipedia.org/wiki/Bayesian_inference_in_phylogeny#:~:text=Bayesian%20inference%20of%20phylogeny%20combines,prior%20and%20the%20likelihood%20model.) is more of a domain general method [see @huelsenbeck2001 for a general introduction to this method]. Its first debut was in evolutionary biology and was later applied in linguistics; it is sometimes termed *Bayesian Phylolinguistics*, see @greenhill2020 for details. By definition, Bayesian phylogenetics has its roots in [Bayes Theorom](https://en.wikipedia.org/wiki/Bayes%27_theorem), which estimates the posterior probability of a phylogenetic tree given the prior probability of the tree and the likelihood to produce such a tree in light of the data. 

\begin{equation}
 \Pr(Tree|Data)=\frac{\Pr(Data|Tree) \times \Pr(Tree)}{\Pr(Data)}
\end{equation}

The prior refers to a set of parameters that we assume from the data, such as tree structure, rate of change, evolution model, branch length, and etc. The posterior refers to how likely phylogenies inferred from the data are correct. The posterior probability involves computation-intensive calculation, which cannot be easily done analytically [@huelsenbeck2001]; [Markov Chain Monte Carlo (MCMC)](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo) is often coupled with Bayesian phylogenetics to speed up the estimation of posterior distribution. MCMC starts with a random tree or *step* with an often random set of model parameters to calculate the likelihood of a phylogenetic tree [@greenhill2020]. The likelihood score is constantly evaluated and updated as the algorithm moves on to the next state. If the likelihood score of the current step is higher, then relevant parameters are cached; if not, then they are discarded [@greenhill2020]. The purpose of this searching process, which takes up most of the run time, is to obtain a posterior distribution that best approximates the data and left unchanged when preceding to the next step [@greenhill2020]. The end product of Bayesian phylogenetic inference is a set of possible trees and posterior probabilities of clades. A consensus tree is a collection of representative trees, which often provides a general picture of subgrouping. 

There exists a number of software and/or packages to implement Bayesian phylogenetics, such as [MrBayes](https://nbisweden.github.io/MrBayes/) [@ronquist2003], [RevBayes](https://revbayes.github.io/) [@hohna2016], and [BEAST 2](http://www.beast2.org/) [@bouckaert2014beast]. These tools are largely domain general or specific to evolutionary biology; see their homepages for tutorials and workshops. [BEASTling](https://beastling.readthedocs.io/en/latest/index.html) [@maurits2017], which is introduced in this tutorial, is primarily linguist-oriented. 

## Other appraoches

Leveraging computation power, Bayesian-MCMC methods are able to derive countless phylogenetic trees. Distance-based methods such as *UPGMA*^[Unweighted Pair Group Method with Arithmetic Mean] or in generally accepted term *clustering analysis*, which are often implemented with R [@rcoreteam], do not generate thousands of trees given prior probabilities. These methods estimate lineage-splitting based on similarity (i.e. shared traits) between languages. The major issue of such methods lies in that it assumes an equal rate of change among languages, which could potentially be wide of the mark for datasets like Indo-European languages [@goldstein2020]. Distance-based methods are not covered in the tutorial; see @johnson2011 [pp.182-208] and @goldstein2020 for detailed introductions and tutorials of implementing these methods with R [@rcoreteam]. 
